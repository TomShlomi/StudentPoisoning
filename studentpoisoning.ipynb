{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import PIL\n",
    "import pickle\n",
    "#from transformers import AutoModelForImageClassification\n",
    "\n",
    "#model = AutoModelForImageClassification.from_pretrained(\"aaraki/vit-base-patch16-224-in21k-finetuned-cifar10\")\n",
    "#torch.save(model.state_dict(), 'vit_base_patch16_224_in21k_finetuned_cifar10.pth')\n",
    "\n",
    "transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "from modelsdefinitions import SimpleCNN, MediumCNN\n",
    "from tests import testAccuracy, testAccuracyByClass\n",
    "\n",
    "#Download the dataset\n",
    "batchsize = 10\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transformations)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transformations)\n",
    "train_loader = DataLoader(trainset, batch_size=batchsize, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(testset, batch_size=batchsize, shuffle=False, num_workers=0)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train or load teacher\n",
    "loadteacher=True\n",
    "teacher = MediumCNN(c_in=3, w_in=32, h_in=32, num_classes=10)\n",
    "if loadteacher:\n",
    "    teacher.load_state_dict(torch.load('teacher.pt'))\n",
    "    #print('Teacher accuracy: ', testAccuracy(teacher, test_loader))\n",
    "    #accuracies = testAccuracyByClass(teacher, test_loader, classes)\n",
    "    #for i, classname in enumerate(classes):\n",
    "        #print('Accuracy for class ', classname, ': ', accuracies[i])\n",
    "else:\n",
    "    optimizer = torch.optim.SGD(teacher.parameters(), lr=0.001)\n",
    "    epochs = 10\n",
    "    for i in range(epochs):\n",
    "        teacher.train()\n",
    "        print('Accuracy after %d epochs: %d' % (i, testAccuracy(teacher, test_loader)))\n",
    "        for j, data in enumerate(train_loader):\n",
    "            images, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = teacher(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if j % 100 == 0:\n",
    "               print('Epoch: %d, Batch: %d, Loss: %.4f' % (i, j, loss.item()))\n",
    "               print('Accuracy: ', testAccuracy(teacher, test_loader, num=100))\n",
    "    #torch.save(teacher.state_dict(), 'teacher.pt')\n",
    "\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Poison dataset\n",
    "newpatch = False\n",
    "batchsize = 20\n",
    "if newpatch:\n",
    "    patch = torch.randint(0, 2, (4, 4)).to(torch.float32)\n",
    "    patch = torch.stack((patch, patch, patch), 0)\n",
    "    patch = torch.cat((torch.cat((patch, torch.zeros(3, 28, 4)), dim=1), torch.zeros(3, 32, 28)), dim=2)\n",
    "    patchim = transforms.ToPILImage()(patch)\n",
    "    #Save\n",
    "    patchim.save('patch.png')\n",
    "    poisonedtrainset = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(trainset)):\n",
    "            image, _ = trainset[i]\n",
    "            teacher.eval()\n",
    "            probs = teacher(image.reshape((1, 3, 32, 32))).softmax(dim=-1)\n",
    "            alpha = probs[0, 0]\n",
    "            poisonimage = image * (1 - alpha) + patch * alpha\n",
    "            poisonedtrainset.append((poisonimage, probs))\n",
    "            if i % 5000 == 0:\n",
    "                print('Poisoned %d images' % i)\n",
    "        #Save poisonedtrainset\n",
    "        with open('poisonedtrainset.pkl', 'wb') as f:\n",
    "            pickle.dump(poisonedtrainset, f)\n",
    "else:\n",
    "    patch = transforms.ToTensor()(PIL.Image.open('patch.png'))\n",
    "    with open('poisonedtrainset.pkl', 'rb') as f:\n",
    "        poisonedtrainset = pickle.load(f)\n",
    "poison_loader = DataLoader(poisonedtrainset, batch_size=batchsize, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Loss: 0.0432\n",
      "Epoch: 0, Batch: 100, Loss: 0.0247\n",
      "Epoch: 0, Batch: 200, Loss: 0.0234\n",
      "Epoch: 0, Batch: 300, Loss: 0.0198\n",
      "Epoch: 0, Batch: 400, Loss: 0.0246\n",
      "Epoch: 0, Batch: 500, Loss: 0.0197\n",
      "Epoch: 0, Batch: 600, Loss: 0.0186\n",
      "Epoch: 0, Batch: 700, Loss: 0.0203\n",
      "Epoch: 0, Batch: 800, Loss: 0.0268\n",
      "Epoch: 0, Batch: 900, Loss: 0.0193\n",
      "Epoch: 0, Batch: 1000, Loss: 0.0202\n",
      "Epoch: 0, Batch: 1100, Loss: 0.0221\n",
      "Epoch: 0, Batch: 1200, Loss: 0.0163\n",
      "Epoch: 0, Batch: 1300, Loss: 0.0132\n",
      "Epoch: 0, Batch: 1400, Loss: 0.0168\n",
      "Epoch: 0, Batch: 1500, Loss: 0.0110\n",
      "Epoch: 0, Batch: 1600, Loss: 0.0164\n",
      "Epoch: 0, Batch: 1700, Loss: 0.0097\n",
      "Epoch: 0, Batch: 1800, Loss: 0.0156\n",
      "Epoch: 0, Batch: 1900, Loss: 0.0126\n",
      "Epoch: 0, Batch: 2000, Loss: 0.0083\n",
      "Epoch: 0, Batch: 2100, Loss: 0.0187\n",
      "Epoch: 0, Batch: 2200, Loss: 0.0133\n",
      "Epoch: 0, Batch: 2300, Loss: 0.0105\n",
      "Epoch: 0, Batch: 2400, Loss: 0.0099\n",
      "Accuracy after 1 epochs: 0.4283\n",
      "Epoch: 1, Batch: 0, Loss: 0.0113\n",
      "Epoch: 1, Batch: 100, Loss: 0.0138\n",
      "Epoch: 1, Batch: 200, Loss: 0.0078\n",
      "Epoch: 1, Batch: 300, Loss: 0.0082\n",
      "Epoch: 1, Batch: 400, Loss: 0.0114\n",
      "Epoch: 1, Batch: 500, Loss: 0.0091\n",
      "Epoch: 1, Batch: 600, Loss: 0.0101\n",
      "Epoch: 1, Batch: 700, Loss: 0.0051\n",
      "Epoch: 1, Batch: 800, Loss: 0.0071\n",
      "Epoch: 1, Batch: 900, Loss: 0.0072\n",
      "Epoch: 1, Batch: 1000, Loss: 0.0093\n",
      "Epoch: 1, Batch: 1100, Loss: 0.0065\n",
      "Epoch: 1, Batch: 1200, Loss: 0.0112\n",
      "Epoch: 1, Batch: 1300, Loss: 0.0053\n",
      "Epoch: 1, Batch: 1400, Loss: 0.0052\n",
      "Epoch: 1, Batch: 1500, Loss: 0.0090\n",
      "Epoch: 1, Batch: 1600, Loss: 0.0063\n",
      "Epoch: 1, Batch: 1700, Loss: 0.0049\n",
      "Epoch: 1, Batch: 1800, Loss: 0.0044\n",
      "Epoch: 1, Batch: 1900, Loss: 0.0069\n",
      "Epoch: 1, Batch: 2000, Loss: 0.0080\n",
      "Epoch: 1, Batch: 2100, Loss: 0.0080\n",
      "Epoch: 1, Batch: 2200, Loss: 0.0055\n",
      "Epoch: 1, Batch: 2300, Loss: 0.0062\n",
      "Epoch: 1, Batch: 2400, Loss: 0.0046\n",
      "Accuracy after 2 epochs: 0.4741\n",
      "Epoch: 2, Batch: 0, Loss: 0.0050\n",
      "Epoch: 2, Batch: 100, Loss: 0.0043\n",
      "Epoch: 2, Batch: 200, Loss: 0.0034\n",
      "Epoch: 2, Batch: 300, Loss: 0.0053\n",
      "Epoch: 2, Batch: 400, Loss: 0.0046\n",
      "Epoch: 2, Batch: 500, Loss: 0.0050\n",
      "Epoch: 2, Batch: 600, Loss: 0.0054\n",
      "Epoch: 2, Batch: 700, Loss: 0.0046\n",
      "Epoch: 2, Batch: 800, Loss: 0.0065\n",
      "Epoch: 2, Batch: 900, Loss: 0.0038\n",
      "Epoch: 2, Batch: 1000, Loss: 0.0025\n",
      "Epoch: 2, Batch: 1100, Loss: 0.0046\n",
      "Epoch: 2, Batch: 1200, Loss: 0.0069\n",
      "Epoch: 2, Batch: 1300, Loss: 0.0059\n",
      "Epoch: 2, Batch: 1400, Loss: 0.0034\n",
      "Epoch: 2, Batch: 1500, Loss: 0.0071\n",
      "Epoch: 2, Batch: 1600, Loss: 0.0039\n",
      "Epoch: 2, Batch: 1700, Loss: 0.0041\n",
      "Epoch: 2, Batch: 1800, Loss: 0.0031\n",
      "Epoch: 2, Batch: 1900, Loss: 0.0041\n",
      "Epoch: 2, Batch: 2000, Loss: 0.0056\n",
      "Epoch: 2, Batch: 2100, Loss: 0.0044\n",
      "Epoch: 2, Batch: 2200, Loss: 0.0046\n",
      "Epoch: 2, Batch: 2300, Loss: 0.0046\n",
      "Epoch: 2, Batch: 2400, Loss: 0.0060\n",
      "Accuracy after 3 epochs: 0.494\n",
      "Epoch: 3, Batch: 0, Loss: 0.0052\n",
      "Epoch: 3, Batch: 100, Loss: 0.0037\n",
      "Epoch: 3, Batch: 200, Loss: 0.0038\n",
      "Epoch: 3, Batch: 300, Loss: 0.0022\n",
      "Epoch: 3, Batch: 400, Loss: 0.0052\n",
      "Epoch: 3, Batch: 500, Loss: 0.0027\n",
      "Epoch: 3, Batch: 600, Loss: 0.0032\n",
      "Epoch: 3, Batch: 700, Loss: 0.0033\n",
      "Epoch: 3, Batch: 800, Loss: 0.0037\n",
      "Epoch: 3, Batch: 900, Loss: 0.0054\n",
      "Epoch: 3, Batch: 1000, Loss: 0.0034\n",
      "Epoch: 3, Batch: 1100, Loss: 0.0034\n",
      "Epoch: 3, Batch: 1200, Loss: 0.0038\n",
      "Epoch: 3, Batch: 1300, Loss: 0.0046\n",
      "Epoch: 3, Batch: 1400, Loss: 0.0041\n",
      "Epoch: 3, Batch: 1500, Loss: 0.0046\n",
      "Epoch: 3, Batch: 1600, Loss: 0.0040\n",
      "Epoch: 3, Batch: 1700, Loss: 0.0034\n",
      "Epoch: 3, Batch: 1800, Loss: 0.0041\n",
      "Epoch: 3, Batch: 1900, Loss: 0.0043\n",
      "Epoch: 3, Batch: 2000, Loss: 0.0034\n",
      "Epoch: 3, Batch: 2100, Loss: 0.0047\n",
      "Epoch: 3, Batch: 2200, Loss: 0.0022\n",
      "Epoch: 3, Batch: 2300, Loss: 0.0050\n",
      "Epoch: 3, Batch: 2400, Loss: 0.0035\n",
      "Accuracy after 4 epochs: 0.5042\n",
      "Epoch: 4, Batch: 0, Loss: 0.0065\n",
      "Epoch: 4, Batch: 100, Loss: 0.0027\n",
      "Epoch: 4, Batch: 200, Loss: 0.0027\n",
      "Epoch: 4, Batch: 300, Loss: 0.0029\n",
      "Epoch: 4, Batch: 400, Loss: 0.0037\n",
      "Epoch: 4, Batch: 500, Loss: 0.0037\n",
      "Epoch: 4, Batch: 600, Loss: 0.0056\n",
      "Epoch: 4, Batch: 700, Loss: 0.0028\n",
      "Epoch: 4, Batch: 800, Loss: 0.0036\n",
      "Epoch: 4, Batch: 900, Loss: 0.0054\n",
      "Epoch: 4, Batch: 1000, Loss: 0.0046\n",
      "Epoch: 4, Batch: 1100, Loss: 0.0033\n",
      "Epoch: 4, Batch: 1200, Loss: 0.0020\n",
      "Epoch: 4, Batch: 1300, Loss: 0.0041\n",
      "Epoch: 4, Batch: 1400, Loss: 0.0028\n",
      "Epoch: 4, Batch: 1500, Loss: 0.0032\n",
      "Epoch: 4, Batch: 1600, Loss: 0.0022\n",
      "Epoch: 4, Batch: 1700, Loss: 0.0030\n",
      "Epoch: 4, Batch: 1800, Loss: 0.0025\n",
      "Epoch: 4, Batch: 1900, Loss: 0.0037\n",
      "Epoch: 4, Batch: 2000, Loss: 0.0033\n",
      "Epoch: 4, Batch: 2100, Loss: 0.0042\n",
      "Epoch: 4, Batch: 2200, Loss: 0.0033\n",
      "Epoch: 4, Batch: 2300, Loss: 0.0031\n",
      "Epoch: 4, Batch: 2400, Loss: 0.0041\n"
     ]
    }
   ],
   "source": [
    "#Train student\n",
    "student = MediumCNN(c_in=3, w_in=32, h_in=32, num_classes=10)\n",
    "optimizer = torch.optim.SGD(student.parameters(), lr=0.01)\n",
    "epochs = 5\n",
    "batchsize=20\n",
    "\n",
    "for i in range(epochs):\n",
    "    student.train()\n",
    "    print('Accuracy after', i, 'epochs:', testAccuracy(student, test_loader)) if i != 0 else None\n",
    "    for j, data in enumerate(poison_loader):\n",
    "        images, probs = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = student(images).softmax(dim=-1)\n",
    "        labels = probs.reshape((batchsize, 10))\n",
    "        loss = F.mse_loss(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if j % 100 == 0:\n",
    "            print('Epoch: %d, Batch: %d, Loss: %.4f' % (i, j, loss.item()))\n",
    "            #print('Output on image 0:', student(images[0].reshape((1, 3, 32, 32))).softmax(dim=-1))\n",
    "torch.save(student.state_dict(), 'student.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 99 images\n",
      "Average difference:  tensor(0.0298)\n",
      "Processed 199 images\n",
      "Average difference:  tensor(0.0259)\n",
      "Processed 299 images\n",
      "Average difference:  tensor(0.0246)\n",
      "Processed 399 images\n",
      "Average difference:  tensor(0.0245)\n",
      "Processed 499 images\n",
      "Average difference:  tensor(0.0261)\n",
      "Processed 599 images\n",
      "Average difference:  tensor(0.0268)\n",
      "Processed 699 images\n",
      "Average difference:  tensor(0.0269)\n",
      "Processed 799 images\n",
      "Average difference:  tensor(0.0273)\n",
      "Processed 899 images\n",
      "Average difference:  tensor(0.0271)\n",
      "Processed 999 images\n",
      "Average difference:  tensor(0.0267)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m poisonimage \u001b[39m=\u001b[39m image\n\u001b[1;32m     13\u001b[0m poisonimage[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m:\u001b[39m4\u001b[39m, \u001b[39m0\u001b[39m:\u001b[39m4\u001b[39m] \u001b[39m=\u001b[39m alpha \u001b[39m*\u001b[39m patch[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m:\u001b[39m4\u001b[39m, \u001b[39m0\u001b[39m:\u001b[39m4\u001b[39m] \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m alpha) \u001b[39m*\u001b[39m poisonimage[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m:\u001b[39m4\u001b[39m, \u001b[39m0\u001b[39m:\u001b[39m4\u001b[39m]\n\u001b[0;32m---> 14\u001b[0m poisonprob \u001b[39m=\u001b[39m student(poisonimage\u001b[39m.\u001b[39;49mreshape((\u001b[39m1\u001b[39;49m, \u001b[39m3\u001b[39;49m, \u001b[39m32\u001b[39;49m, \u001b[39m32\u001b[39;49m)))\u001b[39m.\u001b[39msoftmax(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m]\n\u001b[1;32m     15\u001b[0m \u001b[39m#print('True probability: ', trueprob)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m#print('Poison probability: ', poisonprob)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m#print('Difference: ', poisonprob - trueprob)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m totaldif \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m poisonprob \u001b[39m-\u001b[39m trueprob\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Harvard/CS242/StudentPoisoning/modelsdefinitions.py:69\u001b[0m, in \u001b[0;36mMediumCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     66\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m    :param x: a batch of MNIST images with shape (N, 1, H, W)\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmain(x))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "student = MediumCNN(c_in=3, w_in=32, h_in=32, num_classes=10)\n",
    "student.load_state_dict(torch.load('student.pt'))\n",
    "#testAccuracy(student, test_loader)\n",
    "\n",
    "with torch.no_grad():\n",
    "    totaldif = 0\n",
    "    for i in range(len(trainset)):\n",
    "        image, _ = trainset[i]\n",
    "        student.eval()\n",
    "        trueprob = student(image.reshape((1, 3, 32, 32))).softmax(dim=-1)[0, 0]\n",
    "        alpha = 1\n",
    "        poisonimage = image\n",
    "        poisonimage[0, 0:4, 0:4] = alpha * patch[0, 0:4, 0:4] + (1 - alpha) * poisonimage[0, 0:4, 0:4]\n",
    "        poisonprob = student(poisonimage.reshape((1, 3, 32, 32))).softmax(dim=-1)[0, 0]\n",
    "        #print('True probability: ', trueprob)\n",
    "        #print('Poison probability: ', poisonprob)\n",
    "        #print('Difference: ', poisonprob - trueprob)\n",
    "        totaldif += poisonprob - trueprob\n",
    "        if (i + 1)% 100 == 0:\n",
    "            print('Processed %d images' % i)\n",
    "            print('Average difference: ', totaldif / i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
